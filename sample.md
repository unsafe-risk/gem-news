# [GDC] Weekly Newsletter #1

## TiDB 벡터 검색 공개 베타 출시 및 AI 생태계 통찰

### Summary

PingCAP은 TiDB 벡터 검색의 공개 베타 출시를 발표하고 AI 생태계에 대한 통찰력을 공유했습니다. TiDB는 분산형 데이터베이스로, AI 애플리케이션의 요구 사항을 충족하도록 설계되었으며, 벡터 검색 기능을 통합하여 LLM 애플리케이션의 성능을 향상시키고 있습니다. 이 문서에서는 TiDB 벡터 검색의 주요 기능, 사용 사례 및 AI 생태계와의 통합에 대해 자세히 설명합니다.

### Description

TiDB는 PingCAP에서 개발한 오픈소스 분산형 데이터베이스입니다. TiDB는 높은 성능, 확장성 및 가용성을 제공하며,  SQL과 호환되어 기존 애플리케이션을 쉽게 마이그레이션할 수 있습니다. TiDB 벡터 검색은 TiDB의 기능을 확장하여 벡터 데이터를 효율적으로 저장하고 검색할 수 있도록 지원합니다. 이를 통해 LLM 애플리케이션은 더 빠르고 정확하게 데이터에 액세스하고 처리할 수 있습니다.

### Discussion

1. **벡터 검색의 중요성**: AI 애플리케이션, 특히 LLM은 대량의 데이터를 효과적으로 검색하고 처리해야 하는데, 벡터 검색은 이러한 요구 사항을 충족하는 데 필수적인 기술입니다.
2. **TiDB 벡터 검색의 장점**: TiDB 벡터 검색은 TiDB의 분산형 아키텍처 및 SQL 호환성을 활용하여 고성능, 확장성 및 가용성을 제공합니다. 또한, TiDB의 기존 기능과 통합되어 사용자 친화적인 환경을 제공합니다.
3. **AI 생태계와의 통합**: TiDB 벡터 검색은 AWS 및 LlamaIndex와 같은 AI 플랫폼과 통합되어, 사용자는 쉽게 TiDB 벡터 검색을 AI 애플리케이션에 통합할 수 있습니다.

### Features

- 고성능 벡터 데이터 저장 및 검색
- TiDB의 분산형 아키텍처 및 SQL 호환성 활용
- AI 플랫폼과의 통합

### Usage

#### 설치

TiDB 벡터 검색은 TiDB 설치 및 구성 후 별도로 설치할 수 있습니다. 설치 및 구성 지침은 TiDB 문서를 참조하십시오.

#### 벡터 데이터 저장 및 검색

TiDB SQL을 사용하여 벡터 데이터를 저장하고 검색할 수 있습니다. TiDB는 벡터 데이터를 위한 특수 데이터 유형을 제공하며, 다양한 벡터 검색 함수를 지원합니다.

#### AI 애플리케이션과의 통합

TiDB 벡터 검색은 Python, Java, Go 등 다양한 프로그래밍 언어를 지원하는 드라이버를 제공합니다. AI 애플리케이션에서 TiDB 벡터 검색을 사용하여 데이터 저장, 쿼리 및 분석을 수행할 수 있습니다.

### Recommendation

AI 애플리케이션에 적합한 고성능 분산형 데이터베이스와 벡터 검색 기능을 찾고 있다면 TiDB 벡터 검색을 고려해 볼 만합니다. TiDB 벡터 검색은 높은 성능, 확장성 및 가용성을 제공하며, 오픈소스 프로젝트로 사용자 커뮤니티의 지원을 받습니다.

### External Links

- [TiDB 웹사이트](https://www.pingcap.com/en/products/tidb/)
- [TiDB 문서](https://docs.pingcap.com/tidb/stable/)

### Caution

- TiDB 벡터 검색은 아직 베타 버전으로, 모든 기능이 완벽하게 구현되지 않았을 수 있습니다.
- TiDB 벡터 검색은 분산형 데이터베이스로, 복잡한 환경 설정이 필요할 수 있습니다.
## SimpleDB: 스크래치부터 만든 기본 RDBMS

### 요약

이 글은 UCLA에서 데이터베이스 수업을 들으면서 데이터베이스 내부 작동 방식에 대한 이해가 부족했던 저자가 기본적인 데이터베이스를 직접 만들어보면서 데이터베이스의 기본 원리를 배우게 된 경험을 공유합니다. MIT의 데이터베이스 시스템 강좌를 참고하여 구현한 SimpleDB는 SQL 쿼리 파서, 트랜잭션, 쿼리 최적화 기능을 갖춘 기본적인 RDBMS입니다. 

### 설명

SimpleDB는 저자가 데이터베이스의 내부 작동 방식을 더 잘 이해하기 위해 스크래치부터 구현한 기본적인 RDBMS입니다. 이 글에서는 SimpleDB의 아키텍처와 구현 과정을 자세히 설명하며, 데이터베이스의 기본 원리를 이해하는 데 도움을 주고자 합니다.

### 논의

1. **데이터 저장 및 액세스 방식:** SimpleDB는 데이터 행을 튜플로, 튜플의 각 열 값을 필드로 표현합니다. 현재 구현은 문자열과 정수 필드만 지원하며, 동일한 스키마를 가진 튜플은 필드 값과 관계없이 동일한 바이트 수를 사용합니다. 튜플은 페이지에 저장되며, 페이지는 디스크에 저장됩니다. 동일한 테이블에 속하는 페이지는 DbFile 객체로 그룹화되며, 이 객체는 페이지와 튜플을 디스크에 읽고 쓰는 인터페이스를 제공합니다. 
2. **연산자:** SQL 쿼리는 쿼리 파서에 의해 관계 대수 연산자 트리로 표현된 논리적 계획으로 변환됩니다. 쿼리 최적화기는 이 논리적 계획을 동등성 규칙과 비용 기반 최적화를 적용하여 물리적 계획으로 변환합니다. 물리적 계획은 DBIterator 물리적 연산자로 구성됩니다. 현재 SimpleDB는 순차 테이블 스캔, 삽입, 삭제, 정렬, 필터링, 프로젝션, 집계, 중첩 루프 조인, 해시 조인 등의 물리적 연산자를 지원합니다. DBIterator 인터페이스는 물리적 연산자가 자식 노드에서 튜플을 가져오는 데 사용되는 hasNext() 및 next() 함수를 제공합니다.
3. **쿼리 최적화:** 쿼리 최적화기는 논리적 계획을 입력으로 받아 가장 저렴한 물리적 계획으로 변환합니다. 물리적 계획의 비용을 추산하려면 테이블 크기, 데이터 치우침과 같은 통계가 필요합니다. TableStats는 주어진 테이블의 각 열에 대한 히스토그램을 계산하고 이 통계는 선택성, 스캔 비용, 카디널리티를 추정하는 데 사용됩니다. SimpleDB는 Selinger 최적화를 사용하여 쿼리에서 여러 조인을 순서대로 정렬하는 가장 저렴한 방법을 결정합니다. 
4. **트랜잭션:** 트랜잭션은 SimpleDB 쿼리에 ACID 속성을 제공합니다. 트랜잭션은 마치 단일, 불가분의 작업처럼 실행된 것처럼 보여야 합니다. 트랜잭션은 병렬로 실행되므로 데이터 레이스를 방지하기 위해 일종의 잠금이 필요합니다. SimpleDB는 엄격한 2PL(Two-Phase Locking)을 사용하여 동시성 제어를 수행하고 페이지 수준에서 데이터를 잠급니다. LockManager는 여러 읽기 작업이 동시에 동일한 데이터에 액세스할 수 있도록 공유 잠금과 독점 잠금을 모두 지원합니다. 잠금은 BufferPool에서 페이지를 가져올 때 획득되며, 페이지 가져오기 함수는 LockManager에서 페이지의 잠금을 획득할 때까지 차단됩니다. 이러한 차단 방식은 교착 상태의 위험이 있으므로 SimpleDB는 위상 순서 정렬을 통해 교착 상태를 감지하는 DependencyGraph를 구현합니다. 페이지를 가져오는 작업으로 인해 교착 상태가 발생하면 해당 트랜잭션은 중단됩니다. 트랜잭션이 완료되면 트랜잭션이 보유한 모든 잠금이 해제됩니다.

### 기능

- 스크래치부터 구현한 기본적인 RDBMS
- SQL 쿼리 파서, 튜플 관리, 트랜잭션 지원
- 쿼리 최적화 기능
- 관계 대수 연산자와 물리적 DBIterator 연산자 지원

### 사용 방법

SimpleDB를 실행하려면 GitHub에서 저장소를 복제하고 다음 명령을 실행하여 SimpleDB REPL을 시작하면 됩니다.

```bash
ant
java -jar dist/simpledb.jar parser nsf.schema
```

REPL에서 쿼리를 입력할 수 있습니다. 예를 들어, 다음 쿼리를 입력해 볼 수 있습니다.

```sql
SELECT g.title FROM grants g WHERE g.title LIKE 'Monkey';
```

### 추천

SimpleDB는 데이터베이스의 내부 작동 방식에 대한 이해를 높이고자 하는 개발자에게 유용한 프로젝트입니다. SimpleDB는 기본적인 RDBMS를 구현하는 데 필요한 기본 원리를 배우는 데 도움을 주며, ACID 속성, 잠금, 쿼리 최적화 등의 개념을 이해하는 데 도움을 줄 수 있습니다.

### 외부 링크

- [SimpleDB GitHub 저장소](https://github.com/awelm/simpledb)
- [MIT 데이터베이스 시스템 강좌](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-830-database-systems-fall-2010/)
- [관계 대수](https://www.tutorialspoint.com/dbms/relational_algebra.htm)
- [2PL(Two-Phase Locking)](https://www.geeksforgeeks.org/two-phase-locking-protocol/)

### 주의

SimpleDB는 기본적인 데이터베이스 시스템이며, 실제 환경에서 사용하기에는 아직 부족한 기능이 많습니다. 따라서 SimpleDB를 사용하여 실제 애플리케이션을 개발하는 것은 적합하지 않을 수 있습니다. SimpleDB는 데이터베이스의 기본 원리를 배우고 이해하는 데 도움을 주는 교육용 프로젝트로 사용하는 것이 좋습니다.
## 아파치 카프카: 초보자를 위한 튜토리얼

### 요약

아파치 카프카는 실시간 데이터 파이프라인, 데이터 통합 및 이벤트 기반 시스템에 사용되는 데이터 스트리밍 시스템입니다. 이 튜토리얼은 카프카의 작동 방식과 예시 및 활용 사례를 통해 카프카를 처음 접하는 사용자를 위한 가이드를 제공합니다.

### 설명

카프카는 링크드인에서 대량의 데이터를 처리하기 위해 게시-구독 메시지 시스템으로 개발되었으며, 현재는 포춘 100대 기업의 80% 이상이 사용하는 오픈 소스 분산 이벤트 스트리밍 플랫폼입니다. 카프카는 높은 처리량, 장애 허용성, 복원력 및 확장성을 제공하여 다양한 분야에서 활용됩니다.

### 논의

1. **이벤트 스트리밍 플랫폼이란 무엇인가?**
    - 이벤트 스트리밍 플랫폼은 실시간으로 생성되는 데이터 스트림을 수집, 처리, 저장 및 통합하는 시스템입니다.
    - 이벤트는 소프트웨어 또는 애플리케이션에서 식별되거나 기록되는 모든 유형의 작업, 사건 또는 변경 사항을 나타냅니다.

2. **카프카의 핵심 개념**
    - **토픽:** 카프카에서 데이터가 저장되는 논리적인 단위로, 테이블과 유사합니다. 각 토픽은 이벤트 로그를 나타냅니다.
    - **파티션:** 토픽은 여러 파티션으로 나뉘어져, 데이터를 분산 저장하고 병렬 처리를 가능하게 합니다.
    - **브로커:** 카프카 클러스터의 물리적인 노드로, 파티션을 호스팅하고 데이터를 읽고 쓰는 요청을 처리합니다.
    - **복제:** 파티션 데이터는 여러 브로커에 복제되어, 장애 발생 시에도 데이터를 안전하게 유지합니다.
    - **생산자:** 카프카 토픽에 데이터를 게시하는 애플리케이션입니다.
    - **소비자:** 카프카 토픽에서 데이터를 구독하고 처리하는 애플리케이션입니다.

3. **카프카의 장점**
    - **높은 처리량:** 초당 수백만 개의 이벤트 처리가 가능합니다.
    - **내구성:** 데이터는 지속적으로 디스크에 저장되어 손실될 위험이 낮습니다.
    - **확장성:** 클러스터를 확장하여 데이터 처리 용량을 늘릴 수 있습니다.
    - **장애 허용성:** 노드가 장애 발생 시에도 데이터가 안전하게 유지됩니다.
    - **유연성:** 다양한 데이터 형식, 프로그래밍 언어 및 통합 방식을 지원합니다.

4. **카프카의 활용 사례**
    - **데이터 통합:** 다양한 소스에서 데이터를 수집하여 통합합니다.
    - **메트릭 및 모니터링:** 실시간 메트릭 수집 및 분석을 통해 시스템 성능을 모니터링합니다.
    - **로그 집계:** 분산 시스템의 로그 데이터를 중앙 집중식으로 수집 및 분석합니다.
    - **스트림 처리:** 실시간 데이터 처리, 이벤트 스트리밍 및 데이터 플로우 프로그래밍을 지원합니다.
    - **게시-구독 메시징:** 비동기식 메시징을 통해 애플리케이션 간의 통신을 처리합니다.

### 기능

- **고성능 데이터 스트리밍:** 높은 처리량, 내구성 및 확장성을 제공합니다.
- **분산 처리:** 여러 노드에 데이터를 분산 저장 및 처리하여 성능을 향상시킵니다.
- **복제:** 데이터 복제를 통해 장애 허용성을 제공합니다.
- **데이터 통합:** Kafka Connect를 통해 다양한 소스 및 대상 시스템과 통합합니다.
- **스키마 레지스트리:** 스키마 관리를 통해 데이터 호환성 문제를 해결합니다.
- **스트림 처리:** Kafka Streams를 통해 실시간 데이터 처리 및 분석을 수행합니다.

### 사용

#### 설치

카프카는 아파치 카프카 웹사이트에서 다운로드하여 설치할 수 있습니다. 설치 방법은 운영 체제 및 환경에 따라 다릅니다.

#### 카프카 생산자

생산자는 카프카 토픽에 이벤트를 게시하는 역할을 합니다. 다양한 프로그래밍 언어에서 카프카 생산자 라이브러리를 사용하여 데이터를 전송하고 메타데이터를 지정할 수 있습니다.

#### 카프카 소비자

소비자는 카프카 토픽에서 이벤트를 구독하고 처리하는 역할을 합니다. 소비자는 데이터 처리를 위한 구독 방식을 선택할 수 있으며, 데이터 처리 및 오류 처리 기능을 제공합니다.

### 권장 사항

- **카프카 클러스터 설정:** 클러스터 크기, 파티션 수, 복제 수 등을 적절하게 구성해야 합니다.
- **데이터 형식:** 카프카는 특정 데이터 형식을 요구하지 않지만, 효율성을 위해 스키마 정의를 사용하는 것이 좋습니다.
- **스키마 레지스트리 사용:** 스키마 레지스트리를 사용하여 데이터 호환성 문제를 해결하고 데이터를 안전하게 관리합니다.
- **Kafka Connect 활용:** Kafka Connect를 통해 데이터를 카프카에 가져오고 내보내는 작업을 자동화합니다.
- **Kafka Streams 활용:** Kafka Streams를 통해 복잡한 실시간 데이터 처리를 구현합니다.
- **보안 설정:** 필요에 따라 보안 설정을 구성하여 데이터를 보호합니다.
- **모니터링:** 카프카의 성능 및 상태를 모니터링하여 문제를 조기에 발견하고 해결합니다.

### 외부 링크

- [아파치 카프카 공식 웹사이트](https://kafka.apache.org/)
- [컨플루언트 웹사이트](https://www.confluent.io/)

### 주의 사항

- 카프카는 복잡한 시스템이므로, 설치 및 구성에 시간이 소요될 수 있습니다.
- 데이터 손실을 방지하기 위해 적절한 설정 및 관리가 필요합니다.
- 보안 설정은 시스템 보안을 위해 중요합니다.

## 다단계 캐싱: 효율적인 데이터 액세스 전략

### 요약

이 글은 소프트웨어 개발에서 애플리케이션의 모든 계층에서 적용 가능한 캐싱 기술의 중요성과 다단계 캐싱 전략에 대해 설명합니다. 다단계 캐싱은 프론트엔드부터 데이터베이스까지 여러 계층에서 사용되며 각 계층은 데이터 캐싱 패턴에 따라 다르게 활용됩니다. 

### 설명

다단계 캐싱은 일반적으로 프론트엔드, CDN, 로드 밸런서, 서비스 인스턴스, 분산 캐시, 풀텍스트 검색 도구, 데이터베이스 등 여러 수준의 캐시를 사용하여 데이터를 효율적으로 저장하고 빠르게 검색합니다. 각 캐시 수준은 다른 속도, 용량 및 캐싱 규칙을 가지며 데이터 액세스 패턴에 맞게 최적화됩니다.

### 논의

1. **장점**: 다단계 캐싱은 데이터베이스에서 데이터를 가져오는 시간을 단축하여 시스템 성능을 향상시키고 데이터베이스 부담을 줄여 시스템 안정성을 높입니다. 
2. **단점**: 다단계 캐싱은 시스템 복잡성을 증가시키며 각 캐시 수준의 일관성 유지가 어려울 수 있습니다.
3. **구현**: 다단계 캐싱을 구현할 때는 각 캐시 수준의 크기와 캐싱 규칙을 적절히 설정하고 캐시 유효성을 관리하는 것이 중요합니다. 

### 기능

- **빠른 데이터 액세스**: 자주 액세스되는 데이터를 빠르게 제공하여 시스템 성능을 향상시킵니다.
- **데이터베이스 부담 완화**: 데이터베이스에 대한 부담을 줄여 시스템 안정성을 높입니다.
- **유연성**: 다양한 데이터 액세스 패턴에 맞게 캐싱 규칙을 조정할 수 있습니다.

### 사용법

#### 설치

다단계 캐싱을 구현하기 위해 Redis, Memcached, Couchbase 등 다양한 오픈소스 캐싱 도구와 라이브러리를 사용할 수 있습니다.

#### 캐싱 규칙 설정

각 캐시 수준에 대한 캐싱 규칙을 설정해야 합니다. 예를 들어, 가장 빠르고 작은 캐시 수준은 최근에 액세스된 데이터를 저장하고, 느리고 큰 캐시 수준은 오래된 데이터를 저장하도록 설정할 수 있습니다.

#### 캐시 유효성 관리

캐시 유효성을 관리하는 것은 다단계 캐싱의 핵심입니다. 캐시 데이터가 만료되거나 변경될 때 데이터를 업데이트해야 합니다. 

### 권장 사항

- 시스템의 데이터 액세스 패턴을 분석하여 적절한 캐싱 규칙을 설정합니다.
- 각 캐시 수준의 크기와 용량을 신중하게 계획합니다.
- 캐시 유효성을 관리하는 효율적인 메커니즘을 구현합니다.

### 외부 링크

- [System Design Codex](https://systemdesigncodex.com/)
- [Redis](https://redis.io/)
- [Memcached](https://memcached.org/)
- [Couchbase](https://www.couchbase.com/)

### 주의 사항

- 다단계 캐싱은 시스템 복잡성을 증가시킬 수 있습니다.
- 각 캐시 수준의 일관성을 유지하는 것은 어려울 수 있습니다.
- 캐시 데이터의 유효성을 관리하는 것은 중요합니다.
## PostgreSQL의 기본 키: UUID vs. BIGINT

### 요약

이 글은 PostgreSQL 데이터베이스에서 기본 키로 UUID와 BIGINT 중 어떤 것을 사용할지에 대한 딜레마를 다룹니다. 두 데이터 유형 모두 장단점이 있으며, 프로젝트의 특정 요구 사항에 따라 가장 적합한 선택이 달라집니다.

### 설명

PostgreSQL은 안정적인 오픈 소스 관계형 데이터베이스 관리 시스템으로 신뢰성, 성능, 복제 기능으로 잘 알려져 있습니다. 개발자는 종종 기본 키 선택에 어려움을 겪는데, 이는 데이터베이스 성능에 큰 영향을 미칠 수 있습니다. 이 글은 일반적인 PostgreSQL 문제를 다루고 데이터베이스 최적화를 위한 포괄적인 솔루션을 제공합니다.

### 논의

1. **문제 1: 랜덤 UUID를 사용한 느린 INSERT 성능**: PostgreSQL에서 랜덤 UUID를 기본 키로 사용하면 INSERT 성능이 느려지는 경우가 많습니다. 랜덤 UUID는 128비트 값으로 정수보다 생성 속도가 느립니다. 이 문제는 랜덤 UUID가 광범위한 값 범위에 고르게 분포되어 발생합니다. 결과적으로 이러한 UUID를 사용하여 인덱스에 데이터를 삽입하면 데이터 지역성이 좋지 않아 성능이 저하됩니다.
2. **문제 2: UUID의 저장 공간 영향**: UUID는 정수보다 저장 공간이 더 크다는 단점이 있습니다. UUID는 128비트를 사용하는 반면, 정수는 일반적으로 32비트 또는 64비트를 사용합니다. 저장 공간이 늘어나면 디스크 I/O가 증가하고 쿼리 성능이 느려질 수 있습니다.
3. **문제 3: 인덱스 선택**: UUID와 BIGINT 기본 키를 사용할 때는 올바른 인덱스 유형을 선택하는 것이 중요합니다. 기본 키가 일반적으로 단일 키 열로 구성되고 쿼리가 해당 키에 대한 범위 쿼리를 포함하는 경우 B-Tree 인덱스가 가장 적합한 선택입니다.

### 기능

- UUID: 고유 ID 생성
- BIGINT: 적은 저장 공간, 빠른 인덱싱 및 정렬

### 사용

#### 설치

PostgreSQL은 기본적으로 UUID와 BIGINT를 지원합니다. 별도의 설치는 필요하지 않습니다.

#### UUID 사용

UUID를 기본 키로 사용하는 경우 `uuid-ossp` 확장 프로그램을 설치해야 합니다.

```sql
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
```

UUID를 생성하려면 `uuid_generate_v4()` 함수를 사용합니다.

```sql
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  name VARCHAR(255) NOT NULL
);
```

#### BIGINT 사용

BIGINT를 기본 키로 사용하는 경우 `SERIAL` 데이터 유형을 사용하여 자동 증가 시퀀스를 생성할 수 있습니다.

```sql
CREATE TABLE users (
  id SERIAL PRIMARY KEY,
  name VARCHAR(255) NOT NULL
);
```

### 권장 사항

- 고유 ID 생성이 중요한 경우: UUID를 사용합니다.
- 성능이 중요한 경우: BIGINT를 사용합니다.
- 데이터베이스 크기가 큰 경우: BIGINT를 사용합니다.

### 외부 링크

- [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)
- [BIGINT](https://www.postgresql.org/docs/current/datatype-numeric.html)

### 주의 사항

- UUID는 BIGINT보다 더 많은 저장 공간을 차지합니다.
- BIGINT는 자동 증가 시퀀스를 사용하기 때문에 고유한 ID 생성을 위해 추가적인 로직이 필요할 수 있습니다.
- 성능은 데이터베이스의 크기와 쿼리 패턴에 따라 다를 수 있습니다.

## 주의

 - 이 글은 Gemini Flash를 이용하여 생성한 것으로, 사실과 다를 수 있습니다.

## 출처

 - [https://www.pingcap.com/event/tidb-public-beta-launch-and-ai-ecosystem-insights/](https://www.pingcap.com/event/tidb-public-beta-launch-and-ai-ecosystem-insights/)
 - [https://www.awelm.com/posts/simple-db/](https://www.awelm.com/posts/simple-db/)
 - [https://developer.confluent.io/what-is-apache-kafka/?utm_medium=marketingemail&utm_campaign=tm.campaigns_cd.general-welcome-4.0-nurture-email1-prg.global_&utm_source=marketo&utm_content=&utm_keyword=](https://developer.confluent.io/what-is-apache-kafka/?utm_medium=marketingemail&utm_campaign=tm.campaigns_cd.general-welcome-4.0-nurture-email1-prg.global_&utm_source=marketo&utm_content=&utm_keyword=)
 - [https://newsletter.systemdesigncodex.com/p/caching-at-multiple-levels](https://newsletter.systemdesigncodex.com/p/caching-at-multiple-levels)
 - [https://medium.com/@sjksingh/postgresql-primary-key-dilemma-uuid-vs-bigint-52008685b744](https://medium.com/@sjksingh/postgresql-primary-key-dilemma-uuid-vs-bigint-52008685b744)
