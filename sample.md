# [GDC] Weekly Newsletter #1

## TiDB 벡터 검색 공개 베타 출시 및 AI 생태계 인사이트

### Summary

PingCAP은 최근 TiDB 벡터 검색의 공개 베타 버전을 출시하고 AI 생태계에 대한 통찰력을 공유했습니다. TiDB는 분산형 관계형 데이터베이스로, 성능과 확장성이 뛰어나 다양한 애플리케이션에서 사용되고 있습니다. TiDB 벡터 검색은 TiDB에 벡터 검색 기능을 통합하여 LLM 애플리케이션의 검색 및 추론 성능을 향상시킵니다. 이 공개 베타 버전은 개발자들이 TiDB 벡터 검색을 직접 경험하고 피드백을 제공할 수 있는 기회를 제공합니다. 또한, PingCAP은 AI 생태계에 대한 인사이트를 공유하여 TiDB 벡터 검색이 AI 애플리케이션에서 어떻게 사용될 수 있는지 보여주었습니다.

### Description

TiDB 벡터 검색은 TiDB에 벡터 검색 기능을 통합하여 LLM 애플리케이션의 검색 및 추론 성능을 향상시키는 기술입니다. TiDB는 MySQL과 호환되기 때문에 기존 MySQL 애플리케이션을 손쉽게 TiDB 벡터 검색으로 마이그레이션할 수 있습니다.

### Discussion

1. TiDB 벡터 검색의 공개 베타 버전 출시는 개발자들이 TiDB 벡터 검색을 직접 사용해 보고 피드백을 제공할 수 있는 기회를 제공합니다. 이를 통해 TiDB 벡터 검색은 더욱 발전하고 개선될 수 있습니다.
2. PingCAP은 TiDB 벡터 검색을 AI 애플리케이션에 활용할 수 있는 다양한 방법을 제시했습니다. AI 애플리케이션은 대량의 데이터 처리 및 빠른 데이터 분석이 필요하며, TiDB 벡터 검색은 이러한 요구사항을 충족시킬 수 있는 이상적인 솔루션입니다.
3. TiDB는 오픈 소스 프로젝트로, 개발자들은 TiDB의 코드에 접근하고 기여할 수 있습니다. 이는 TiDB 커뮤니티를 더욱 활성화하고 발전시키는 데 기여할 것입니다.

### Features

- 분산형 관계형 데이터베이스
- MySQL 호환성
- 벡터 검색 기능 통합
- 고성능, 확장성, 높은 가용성
- 다양한 AI 애플리케이션 지원

### Usage

#### Installation

TiDB 벡터 검색 설치는 PingCAP 웹사이트에서 다운로드한 설치 가이드를 참조하여 진행할 수 있습니다.

#### 사용 방법

TiDB 벡터 검색은 MySQL과 유사한 쿼리 언어를 사용합니다. 개발자들은 기존 MySQL 애플리케이션을 TiDB 벡터 검색으로 쉽게 마이그레이션할 수 있습니다.

### Recommendation

TiDB 벡터 검색은 대규모 데이터 처리, 고성능 트랜잭션, 확장성, 높은 가용성이 필요한 AI 애플리케이션에 적합한 솔루션입니다. 특히 LLM 애플리케이션의 검색 및 추론 성능을 향상시키는 데 효과적일 수 있습니다.

### External Links

- [TiDB 웹사이트](https://www.pingcap.com/)
- [TiDB GitHub 저장소](https://github.com/pingcap/tidb)

### Caution

- TiDB 벡터 검색은 아직 개발 중이며, 모든 기능이 완벽하게 지원되지 않을 수 있습니다.
- TiDB 벡터 검색을 사용하기 전에 공식 문서를 참조하여 사용 방법 및 제약 사항을 확인해야 합니다. 
## SimpleDB: 스크래치부터 만든 기본적인 RDBMS

### Summary

SimpleDB는 UCLA 데이터베이스 수업에서 학습한 내용을 바탕으로 스크래치부터 구현한 기본적인 관계형 데이터베이스 관리 시스템(RDBMS)입니다. 이 프로젝트는 데이터베이스 내부 동작 방식에 대한 이해를 높이기 위해 진행되었습니다. SimpleDB는 SQL 쿼리 파서, 트랜잭션, 쿼리 최적화 등 기본적인 RDBMS 기능을 포함합니다.

### Description

SimpleDB는 파일에 데이터를 저장하는 방식으로 구현되었으며, 다음과 같은 기능을 제공합니다.

- **데이터 저장 및 액세스 방식**: SimpleDB는 데이터 행을 튜플로 저장하며, 각 튜플은 열 값을 나타내는 필드로 구성됩니다. 현재 문자열 및 정수 필드 타입만 지원합니다. 튜플은 페이지에 저장되고, 페이지는 디스크에 저장됩니다.  각 테이블은 DbFile 객체로 관리되며, 페이지와 튜플을 디스크에 읽고 쓰는 기능을 제공합니다.
- **카탈로그**: SimpleDB는 카탈로그 객체를 통해 새로운 테이블을 추가하고, 스키마 및 기본 키 정보를 관리합니다.
- **버퍼 풀**: 버퍼 풀 객체는 모든 페이지 액세스와 수정을 관리하며, 자주 사용되는 페이지를 메모리에 캐싱합니다. 캐싱된 페이지는 디스크에서 데이터를 가져오는 속도를 높여 성능을 향상시킵니다.
- **쿼리 최적화**: SimpleDB는 SQL 쿼리를 논리적 계획으로 변환한 후, 관계 대수 연산자를 사용하여 물리적 계획으로 변환합니다. 물리적 계획은 쿼리를 실제로 실행하는 역할을 합니다.
- **트랜잭션**: SimpleDB는 트랜잭션을 통해 ACID 속성(원자성, 일관성, 격리성, 내구성)을 보장합니다.  SimpleDB는 2PL(Two-Phase Locking) 방식을 사용하여 데이터 경합을 방지하고, 페이지 수준의 잠금을 사용합니다.
- **쿼리 실행**: SimpleDB는 쿼리 계획을 실행하여 결과를 생성합니다.  여러 종류의 연산자 (순차적 테이블 스캔, 삽입, 삭제, 정렬, 필터, 프로젝션, 집계, 중첩 루프 조인, 해시 조인 등)를 통해 데이터를 처리합니다.

### Discussion

- **장점**: SimpleDB는 데이터베이스의 기본적인 작동 방식을 이해하는 데 도움을 주는 유용한 학습 도구입니다. 
- **단점**: SimpleDB는 아직 초기 단계의 프로젝트이며, 실제 환경에서 사용하기에는 기능 및 성능 측면에서 제한적입니다.
- **대안**: MySQL, PostgreSQL, SQLite 등 다양한 RDBMS가 존재하며, SimpleDB보다 더 많은 기능을 제공합니다.

### Features

- **SQL 쿼리 파서**: SimpleDB는 SQL 쿼리를 파싱하고 해석합니다.
- **트랜잭션 관리**: SimpleDB는 트랜잭션을 지원하며 ACID 속성을 보장합니다.
- **쿼리 최적화**: SimpleDB는 쿼리 계획을 최적화하여 실행 속도를 높입니다.
- **물리적 연산자**: SimpleDB는 쿼리를 실행하는 데 필요한 다양한 물리적 연산자를 제공합니다.

### Usage

#### Installation

- SimpleDB는 Github에서 소스 코드를 다운로드하여 컴파일합니다.

#### 쿼리 실행

- SimpleDB REPL(Read-Eval-Print Loop)을 사용하여 쿼리를 실행할 수 있습니다.

### Recommendation

SimpleDB는 데이터베이스 시스템의 구현 방식에 대한 이해를 높이기 원하는 사람들에게 유용한 프로젝트입니다.

### External Links

- SimpleDB Github Repository: [https://github.com/awelm/simpledb](https://github.com/awelm/simpledb)

### Caution

- SimpleDB는 개발 중인 프로젝트이며, 실제 환경에서 사용하기에는 안정성 및 성능이 충분하지 않습니다.
- SimpleDB는 현재 학습 목적으로만 사용되고 있으며, 실제 서비스 환경에 배포하기 위한 추가 개발이 필요합니다.

## 아파치 카프카: 초보자를 위한 튜토리얼

### Summary

아파치 카프카는 실시간 데이터 파이프라인, 데이터 통합 및 이벤트 기반 시스템에 사용되는 데이터 스트리밍 시스템입니다. 이 튜토리얼은 카프카의 작동 방식, 예제 및 사용 사례를 통해 카프카에 대한 기본적인 이해를 제공합니다. 

### Description

카프카는 링크드인에서 대량의 데이터를 처리하기 위해 게시-구독 메시징 시스템으로 개발되었으며, 오늘날에는 포춘 100대 기업의 80% 이상이 사용하는 오픈 소스 분산 이벤트 스트리밍 플랫폼입니다. 카프카는 실시간 데이터 분석, 이벤트 스트리밍, 데이터 파이프라인 구축 등 다양한 분야에서 활용됩니다.

### Discussion

1. **카프카의 장점:** 높은 처리량, 장애 허용성, 복원력, 확장성, 실시간 데이터 처리, 다양한 사용 사례, 오픈 소스
2. **카프카의 단점:** 복잡한 설정 및 운영, 높은 학습 곡선
3. **카프카의 사용 사례:** 실시간 분석, 이벤트 스트리밍, 로그 처리, 데이터 파이프라인, 메시지 큐, 마이크로 서비스 통신, 데이터 복제

### Features

- **고성능:** 초당 수백만 건의 메시지를 처리할 수 있는 높은 처리량을 제공합니다.
- **분산 처리:** 여러 노드에 분산되어 있어, 단일 지점 장애를 방지하고 확장성을 높입니다.
- **내구성:** 메시지는 디스크에 지속적으로 저장되어 데이터 손실을 방지합니다.
- **실시간 데이터 처리:** 실시간으로 데이터를 처리하고 전송하여 빠른 응답성을 제공합니다.
- **오픈 소스:** 무료로 사용 가능하며, 커뮤니티 지원을 받을 수 있습니다.

### Usage

#### Installation

카프카는 Apache Software Foundation에서 제공하는 오픈 소스 소프트웨어로, 공식 웹사이트에서 다운로드하여 설치할 수 있습니다.

#### 데이터 게시

데이터 게시자는 카프카에 데이터를 전송하여 스트림을 생성합니다.

#### 데이터 구독

데이터 구독자는 카프카에서 스트림을 구독하여 데이터를 수신하고 처리합니다.

### Recommendation

아파치 카프카는 실시간 데이터 처리 및 스트리밍을 위한 강력한 플랫폼입니다. 높은 처리량, 분산 처리, 내구성을 필요로 하는 시스템에 적합하며, 데이터 분석, 이벤트 스트리밍, 데이터 파이프라인 구축 등 다양한 분야에서 활용 가능합니다.

### External Links

- [Apache Kafka 공식 웹사이트](https://kafka.apache.org/)
- [Confluent 웹사이트](https://www.confluent.io/)
- [카프카 문서](https://kafka.apache.org/documentation/)

## 다단계 캐싱: 효율적인 데이터 액세스를 위한 전략

### 요약

이 글은 소프트웨어 개발에서 모든 계층에 적용될 수 있는 캐싱 기법에 대해 자세히 설명합니다. 캐싱은 웹 애플리케이션의 성능을 향상시키는 필수적인 기술이며, 프론트엔드에서 데이터베이스까지 다양한 계층에서 활용될 수 있습니다. 이 글에서는 각 계층에서 캐싱이 어떻게 사용되는지, 그리고 다단계 캐싱 전략이 어떻게 작동하는지 살펴봅니다.

### 설명

다단계 캐싱은 여러 계층의 캐시를 사용하여 데이터 액세스를 최적화하는 기술입니다. 각 계층은 다른 캐싱 메커니즘과 지속 시간을 가지며, 이를 통해 빠른 응답 시간과 높은 처리량을 달성할 수 있습니다. 

* **프론트엔드 애플리케이션:** 웹 브라우저는 HTTP 응답, 자산 파일, HTML 페이지 등을 캐싱합니다. 개발자는 응답 헤더에 캐싱 지시 사항을 설정하여 특정 자산의 캐싱 동작을 제어할 수 있습니다.
* **콘텐츠 전송 네트워크 (CDN):** CDN은 이미지, 스타일시트, JS 파일과 같은 정적 콘텐츠를 캐싱합니다. CDN은 사용자에게 가까운 서버에 콘텐츠를 캐싱하여 네트워크 지연 시간을 줄이는 장점이 있습니다.
* **로드 밸런서:** 일부 로드 밸런서는 자주 액세스하는 데이터를 캐싱할 수 있습니다. 이를 통해 백엔드 서버를 호출하지 않고도 응답을 제공할 수 있으며, 응답 시간을 단축하고 서버 또는 데이터베이스의 부하를 줄일 수 있습니다.
* **서비스 인스턴스 캐시:** 서비스 인스턴스는 성능을 향상시키기 위해 자체 캐싱 솔루션을 사용할 수 있습니다. 이는 데이터베이스에서 데이터를 가져오기 전에 확인하는 인메모리 캐시 또는 분산 캐시의 형태로 제공됩니다.
* **분산 캐시:** Redis와 같은 분산 캐시는 기존 관계형 데이터베이스보다 빠른 읽기 및 쓰기 속도를 제공합니다. 또한, 여러 노드에 걸쳐 캐시를 확장하여 복원력을 높일 수 있습니다.
* **전문 검색 도구:** 텍스트 정보를 대량으로 검색하는 것은 시간이 오래 걸리는 작업입니다. ElasticSearch와 같은 도구는 텍스트 검색을 빠르게 하기 위해 데이터를 색인화하여 사실상 캐시 역할을 합니다.
* **데이터베이스:** 데이터베이스는 디스크에서 항상 데이터를 가져오는 것은 아닙니다. 데이터베이스는 버퍼 풀을 사용하여 빠른 읽기를 지원하고 데이터 페이지를 캐싱합니다. 또한, 물질화된 뷰는 값비싼 쿼리의 사전 계산된 결과를 저장하여 빠른 액세스를 제공합니다. 최신 데이터베이스는 자체 내장 캐시 솔루션을 제공합니다.

### 논의

1. **다단계 캐싱의 장점:** 다단계 캐싱은 데이터 액세스 시간을 단축하고 서버 부하를 줄여 웹 애플리케이션의 성능을 향상시킬 수 있습니다.
2. **다단계 캐싱의 단점:** 다단계 캐싱은 구현 및 관리가 복잡할 수 있으며, 캐시 일관성 문제가 발생할 수 있습니다.
3. **다단계 캐싱의 적용:** 다단계 캐싱은 웹 애플리케이션의 모든 계층에서 적용할 수 있으며, 특히 대량의 사용자 트래픽을 처리하는 애플리케이션에 유용합니다.

### 기능

- 여러 계층의 캐싱을 사용하여 데이터 액세스를 최적화합니다.
- 빠른 응답 시간과 높은 처리량을 제공합니다.
- 서버 부하를 줄이고 애플리케이션 성능을 향상시킵니다.

### 사용법

#### 설치

다단계 캐싱은 사용하는 캐싱 기술과 애플리케이션 아키텍처에 따라 다양한 방법으로 구현될 수 있습니다. 일반적으로 다음과 같은 단계가 포함됩니다.

1. 인메모리 캐시 시스템을 설치하고 구성합니다.
2. 데이터베이스 캐싱 기능을 활성화합니다.
3. CDN 서비스를 설정하고 캐싱 규칙을 구성합니다.

#### 캐싱 규칙 설정

각 캐싱 계층에 적합한 캐싱 규칙을 설정해야 합니다. 예를 들어, 인메모리 캐시는 자주 사용되는 데이터 또는 변동성이 적은 데이터를 캐싱하는 데 적합합니다. 데이터베이스 캐시는 데이터베이스 쿼리 결과를 캐싱하거나, 자주 사용되는 데이터를 캐싱하는 데 적합합니다. CDN 캐시는 정적 콘텐츠, 이미지, 비디오와 같은 대용량 데이터를 캐싱하는 데 적합합니다.

### 추천

다단계 캐싱은 웹 애플리케이션의 성능을 향상시키는 효과적인 기술입니다. 특히 대량의 사용자 트래픽을 처리하는 애플리케이션에 유용합니다. 다단계 캐싱을 구현할 때는 각 계층에 적합한 캐싱 규칙을 설정하고 캐시 일관성 문제를 해결해야 합니다.

### 외부 링크

- [System Design Codex](https://systemdesigncodex.com/)
- [Redis](https://redis.io/)
- [Memcached](https://memcached.org/)
- [Cloudflare](https://www.cloudflare.com/)

### 주의

- 다단계 캐싱은 구현 및 관리가 복잡할 수 있습니다.
- 캐시 일관성 문제가 발생할 수 있습니다.
- 캐시를 잘못 구성하면 성능 저하가 발생할 수 있습니다.

## PostgreSQL의 주요 키 딜레마: UUID vs. BIGINT

### 요약

본 글은 PostgreSQL 데이터베이스에서 주요 키로 UUID와 BIGINT를 사용하는 것에 대한 장단점을 논의합니다. UUID는 전 세계적으로 고유한 식별자를 제공하지만, BIGINT는 성능 측면에서 유리합니다. 저자는 특히 UUID를 사용할 때 발생하는 삽입 성능 저하, 저장 공간 문제, 그리고 인덱스 선택의 어려움을 언급하며, 이에 대한 해결책으로 순차적 UUID 생성, BIGINT 사용, 그리고 B-트리 인덱스 활용을 제시합니다.

### 설명

PostgreSQL은 데이터베이스 테이블의 각 행을 고유하게 식별하기 위해 주요 키를 사용합니다. 가장 일반적인 주요 키 유형은 UUID와 BIGINT입니다. UUID는 128비트 난수로, 전 세계적으로 고유한 식별자를 생성합니다. 반면에 BIGINT는 64비트 정수로, 데이터베이스 내에서 고유하도록 설정됩니다.

### 논의

1. **UUID의 장점:**
    - **전 세계적 고유성:** UUID는 전 세계적으로 고유한 식별자를 제공합니다.
    - **분산 시스템에 적합:** UUID는 여러 서버에서 데이터를 생성하는 분산 시스템에 적합합니다.
    - **테이블 조인 성능 향상:** UUID는 BIGINT보다 테이블 조인 성능을 향상시킬 수 있습니다.

2. **UUID의 단점:**
    - **성능 저하:** UUID는 BIGINT보다 저장 공간을 더 많이 차지하며, 인덱싱 및 검색 성능에 영향을 미칠 수 있습니다.
    - **인덱싱 문제:** UUID는 순차적으로 정렬되지 않으므로, B-트리 인덱싱에 불리할 수 있습니다.

3. **BIGINT의 장점:**
    - **성능 우수:** BIGINT는 UUID보다 저장 공간을 적게 차지하며, 인덱싱 및 검색 성능이 우수합니다.
    - **순차적 정렬:** BIGINT는 순차적으로 정렬되어 B-트리 인덱싱에 유리합니다.

### 기능

- **UUID:** 전 세계적으로 고유한 식별자를 생성합니다.
- **BIGINT:** 64비트 정수로, 데이터베이스 내에서 고유하도록 설정됩니다.

### 사용

#### UUID 사용

```sql
CREATE TABLE my_table (
    id UUID PRIMARY KEY,
    name VARCHAR(255)
);
```

#### BIGINT 사용

```sql
CREATE TABLE my_table (
    id BIGINT PRIMARY KEY,
    name VARCHAR(255)
);
```

### 권장 사항

데이터베이스의 규모와 성능 요구 사항에 따라 UUID 또는 BIGINT를 선택하십시오. 일반적으로, 성능이 중요한 대규모 데이터베이스의 경우 BIGINT를 사용하는 것이 좋습니다.

### 외부 링크

- [PostgreSQL 문서](https://www.postgresql.org/docs/)
- [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)

### 주의 사항

- UUID는 BIGINT보다 저장 공간을 더 많이 차지하므로, 데이터베이스의 크기가 커지면 성능 저하가 발생할 수 있습니다.
- BIGINT는 데이터베이스 내에서만 고유한 식별자를 제공하므로, 분산 시스템에서는 UUID를 사용하는 것이 좋습니다. 
## Go 언어의 `//go:linkname` 사용 제한: 이슈 67401 분석

### Summary

Go 언어의 표준 라이브러리 내부 함수에 대한 의존성을 제한하기 위한 이슈 67401에 대한 분석입니다. 이 이슈는 Go 1.23 릴리즈에서 해결되었으며, `//go:linkname` 지시어를 통해 표준 라이브러리 내부 함수를 직접 사용하는 것을 제한합니다. 이는 Go 생태계의 안정성과 유지보수성을 향상시키기 위한 조치입니다.

### Description

`//go:linkname` 지시어는 Go 코드에서 특정 심볼을 다른 심볼로 연결하는 데 사용됩니다. 표준 라이브러리의 내부 함수는 `//go:linkname`을 통해 외부 패키지에서 직접 접근할 수 있었는데, 이는 표준 라이브러리 변경 시 외부 패키지가 예상치 못하게 동작하지 않을 위험을 야기했습니다.

이 이슈를 해결하기 위해 Go 개발 팀은 `//go:linkname` 사용을 제한하는 새로운 규칙을 도입했습니다. Go 1.23부터는 표준 라이브러리 내부 함수를 `//go:linkname`으로 직접 사용하는 경우 컴파일 오류가 발생합니다. 

### Discussion

1. **외부 패키지의 영향:** `//go:linkname` 사용 제한은 표준 라이브러리에 의존하는 외부 패키지에 큰 영향을 미칠 수 있습니다. 기존에 `//go:linkname`을 통해 표준 라이브러리 내부 함수를 사용했던 외부 패키지는 Go 1.23 이후 호환성 문제를 겪을 수 있습니다. 따라서 외부 패키지 개발자들은 이 변화에 대비해야 합니다.
2. **대안:** `//go:linkname`을 대신 사용할 수 있는 대안으로는 표준 라이브러리에서 제공하는 공식적인 API를 사용하는 방법이 있습니다. 외부 패키지 개발자들은 `//go:linkname`을 사용하지 않고 표준 라이브러리 API를 사용하도록 코드를 수정해야 합니다.
3. **향후 계획:** Go 개발 팀은 `//go:linkname`을 완전히 제거할 계획은 없지만, 표준 라이브러리 외에도 외부 패키지에서 `//go:linkname`을 사용하는 것도 제한할 가능성이 있습니다. 

### Features

- `//go:linkname` 사용 제한
- 표준 라이브러리 내부 함수에 대한 외부 패키지 의존성 제거
- Go 생태계의 안정성 및 유지보수성 향상

### Recommendation

- Go 1.23 이상 버전을 사용하는 것을 권장합니다.
- `//go:linkname`을 사용하는 외부 패키지 개발자는 Go 1.23 호환성 문제를 해결하기 위해 코드를 수정해야 합니다.
- 표준 라이브러리 내부 함수를 사용하는 경우, 공식적인 API를 사용하는 것을 권장합니다.

### External Links

- [Go 이슈 트래커](https://github.com/golang/go/issues/67401)
- [Go 1.23 릴리즈 노트](https://golang.org/doc/go1.23)

### Caution

- Go 1.23 이전 버전에서는 `//go:linkname` 사용에 제한이 없었습니다. 
- `//go:linkname` 사용 제한은 표준 라이브러리에 의존하는 외부 패키지에 영향을 미칠 수 있습니다. 
- `//go:linkname`을 사용하는 외부 패키지 개발자들은 코드를 수정하여 Go 1.23 호환성 문제를 해결해야 합니다. 

## 주의

 - 이 글은 Gemini Flash를 이용하여 생성한 것으로, 사실과 다를 수 있습니다.

## 출처

 - [https://www.pingcap.com/event/tidb-public-beta-launch-and-ai-ecosystem-insights/](https://www.pingcap.com/event/tidb-public-beta-launch-and-ai-ecosystem-insights/)
 - [https://www.awelm.com/posts/simple-db/](https://www.awelm.com/posts/simple-db/)
 - [https://developer.confluent.io/what-is-apache-kafka/?utm_medium=marketingemail&utm_campaign=tm.campaigns_cd.general-welcome-4.0-nurture-email1-prg.global_&utm_source=marketo&utm_content=&utm_keyword=](https://developer.confluent.io/what-is-apache-kafka/?utm_medium=marketingemail&utm_campaign=tm.campaigns_cd.general-welcome-4.0-nurture-email1-prg.global_&utm_source=marketo&utm_content=&utm_keyword=)
 - [https://newsletter.systemdesigncodex.com/p/caching-at-multiple-levels](https://newsletter.systemdesigncodex.com/p/caching-at-multiple-levels)
 - [https://medium.com/@sjksingh/postgresql-primary-key-dilemma-uuid-vs-bigint-52008685b744](https://medium.com/@sjksingh/postgresql-primary-key-dilemma-uuid-vs-bigint-52008685b744)
 - [https://github.com/golang/go/issues/67401](https://github.com/golang/go/issues/67401)
